{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Basic\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from IPython.display import Image, display_png\n",
    "import collections\n",
    "import category_encoders as ce\n",
    "\n",
    "# Sampling or Devison of Data\n",
    "#from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# Parameter Turning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# GBDT\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "\n",
    "# SageMarker\n",
    "import io, boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レコード数とカラム数が多い場合に設定する\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# pandasのフォーマットを変更\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix グラフ\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    #for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    for i, j in ((x,y) for x in range(cm.shape[0]) for y in range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True/Pred 棒グラフ\n",
    "def plot_true_pred_bar(d_true, d_pred):\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(np.array([x for x in collections.Counter(d_true)]) +0.2, np.array([x for x in collections.Counter(d_true).values()]), color=\"#CBDEF0\", width=0.4, label=\"True\")\n",
    "    plt.bar(np.array([x for x in collections.Counter(d_pred)]) -0.2, np.array([x for x in collections.Counter(d_pred).values()]), color=\"#60A6D1\", width=0.4, label=\"Pred\")\n",
    "\n",
    "    plt.xticks(range(0,9))\n",
    "    plt.legend(loc=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 型変換関数\n",
    "def reduce_memory(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Initial df memory usage is {:.2f} MB for {} columns'\n",
    "          .format(start_mem, len(df.columns)))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    memory_reduction = 100 * (start_mem - end_mem) / start_mem\n",
    "    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ定義\n",
    "dtype_dm = {\n",
    "    \"推薦ID\":\"int32\",\n",
    "    \"求人ID\":\"int32\",\n",
    "    \"契約世代ID\":\"int32\",\n",
    "    \"求職者子CD\":\"int32\",\n",
    "    \"決定年収\":\"int32\",\n",
    "    \"入社FLG\":\"int8\",\n",
    "    \"受注額_金額_合計\":\"int32\",\n",
    "    \"採用人数\":\"int16\",\n",
    "    \"転職決定時年齢\":\"int8\",\n",
    "}\n",
    "\n",
    "dtype_ii = {\n",
    "    \"推薦ID\":\"int32\",\n",
    "    \"FLAG_一割以上上\":\"int8\",\n",
    "    \"FLAG_一割以上下\":\"int8\",\n",
    "    \"FLAG_一円でも上\":\"int8\",\n",
    "    \"FLAG_一円でも下\":\"int8\",\n",
    "    \"FLAG_完全一致\":\"int8\",\n",
    "    \"前年収_採用年収\":\"int32\",\n",
    "    \"後年収\":\"int32\",\n",
    "    \"年齢\":\"int16\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::707539689644:role/service-role/AmazonSageMaker-ExecutionRole-20190401T165949'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AWSのrole確認\n",
    "role = get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACD.tsv', 'datamart.txt', 'index_inspect.tsv', 'test_ok_feature.tsv']\n"
     ]
    }
   ],
   "source": [
    "# S3接続\n",
    "s3_client = boto3.client('s3')\n",
    "data_bucket_name='rc-datum-s3'\n",
    "\n",
    "obj_list=s3_client.list_objects(Bucket=data_bucket_name)\n",
    "file=[]\n",
    "for contents in obj_list['Contents']:\n",
    "    file.append(contents['Key'])\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419128, 68)\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.get_object(Bucket=data_bucket_name, Key=file[1])\n",
    "response_body = response[\"Body\"].read()\n",
    "df_dm = pd.read_table(io.BytesIO(response_body), dtype=dtype_dm, low_memory=False) \n",
    "\n",
    "print(df_dm.shape)\n",
    "#display(df_dm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381295, 67)\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.get_object(Bucket=data_bucket_name, Key=file[2])\n",
    "response_body = response[\"Body\"].read()\n",
    "df_ii = pd.read_table(io.BytesIO(response_body), dtype=dtype_ii, low_memory=False) \n",
    "\n",
    "print(df_ii.shape)\n",
    "#display(df_ii.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial df memory usage is 40.09 MB for 9 columns\n",
      "Final memory usage is: 33.41 MB - decreased by 16.7%\n",
      "(583803, 9)\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.get_object(Bucket=data_bucket_name, Key=file[0])\n",
    "response_body = response[\"Body\"].read()\n",
    "df_acd = pd.read_table(io.BytesIO(response_body), low_memory=False) \n",
    "df_acd = reduce_memory(df_acd)\n",
    "\n",
    "print(df_acd.shape)\n",
    "#display(df_acd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### カラム削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419128, 39)\n",
      "(381295, 31)\n",
      "(583803, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(112262, 8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datamart\n",
    "df_dm.drop([\"求人ID\",\"契約世代ID\",\"求職者子CD\"], axis=1, inplace=True)\n",
    "# 代表職種と経験職種名／求人職種コードは中身がほぼ同じなので、代表職種のみ残す\n",
    "df_dm.drop([\"経験職種名\",\"求人職種コード\"], axis=1, inplace=True)\n",
    "df_dm.drop([\"資格2\",\"資格3\",\"資格4\",\"資格5\",\"決定計上日\",\"求人雇用形態\",\"経験業界名2\",\"経験業界名3\",\"経験業界名4\",\"経験業界名5\"], axis=1, inplace=True)\n",
    "df_dm.drop([\"求人先_法人CD\",\"求人先_窓口CD\",\"求人業界2\",\"求人業界3\",\"求人業界4\",\"求人業界5\"], axis=1, inplace=True)\n",
    "df_dm.drop([\"経験業界名1(2008年8月以前取得用)\",\"経験職種名1(代替取得方法)\",\"経験職種名2(代替取得方法)\",\"経験職種名3(代替取得方法)\",\"経験職種名4(代替取得方法)\",\"経験職種名5(代替取得方法)\",\"求人職種(代替取得方法)\",], axis=1, inplace=True)\n",
    "# カラム数が増えるので市区郡は一旦削除する\n",
    "df_dm.drop([\"住所_市区郡\"], axis=1, inplace=True)\n",
    "print(df_dm.shape)\n",
    "#df_dm.head()\n",
    "\n",
    "# index_inspect\n",
    "df_ii.drop([\"FLAG_一割以上上\",\"FLAG_一割以上下\",\"FLAG_一円でも上\",\"FLAG_一円でも下\",\"FLAG_完全一致\",\"前年収_X\",\"前年収_Y\",\"前年収_A\",\"前年収_B\",\"前年収_C\",\"転職後_企業コード\"], axis=1, inplace=True)\n",
    "df_ii.drop([\"統合法人C\",\"顧客Ｃ\",\"帝国Ｃ\"], axis=1, inplace=True)\n",
    "# 従業員数と資本金は明らかに数値がおかしいので、RC社から返答あるまで一旦削除しとく\n",
    "df_ii.drop([\"従業員数＿最新\",\"資本金＿最新\"], axis=1, inplace=True)\n",
    "df_ii.drop([\"決算ＹＭ＿前回\",\"従業員数＿前回\",\"資本金＿前回\",\"年商＿前回\",\"利益額＿前回\",\"申告所得額＿前回\",\"年商伸率＿前回\",\"利益伸率＿前回\",\"評点＿前回\",\"決算ＹＭ＿前々回\",\"従業員数＿前々回\",\"資本金＿前々回\",\"年商＿前々回\",\"利益額＿前々回\",\"申告所得額＿前々回\",\"年商伸率＿前々回\",\"利益伸率＿前々回\",\"評点＿前々回\",], axis=1, inplace=True)\n",
    "# 学歴と性別はdatamartの方を使う\n",
    "df_ii.drop([\"性別\",\"学歴\"], axis=1, inplace=True)\n",
    "print(df_ii.shape)\n",
    "#df_ii.head()\n",
    "\n",
    "# ACD\n",
    "df_acd.drop([\"卒業中退区分\"], axis=1, inplace=True)\n",
    "print(df_acd.shape)\n",
    "#df_acd.head()\n",
    "\n",
    "# ACDは重複データがやたらと多いので、dropnaして減らす\n",
    "df_acd_2 = df_acd.dropna()\n",
    "# 重複行がたくさんあるので、最初だけ残してあとは削除する\n",
    "df_acd_2 = df_acd_2.drop_duplicates(\"求職者親CD\", keep=\"first\")\n",
    "\n",
    "df_acd_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419128, 69)\n",
      "(419128, 76)\n"
     ]
    }
   ],
   "source": [
    "df_ = pd.merge(df_dm, df_ii, on=\"推薦ID\", how=\"left\")\n",
    "print(df_.shape)\n",
    "#df_.head()\n",
    "\n",
    "df_2 = pd.merge(df_, df_acd_2, on=\"求職者親CD\", how=\"left\")\n",
    "print(df_2.shape)\n",
    "#df_2.head()\n",
    "\n",
    "#df_3 = df_2.copy()\n",
    "\n",
    "# 推薦IDと求職者親CDを削除する\n",
    "df_.drop([\"推薦ID\",\"求職者親CD\"], axis=1, inplace=True)\n",
    "df_3 = df_.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前年収と後年収の異常値を丸める\n",
    "df_3.loc[df_3[\"前年収_採用年収\"]>=5000, \"前年収_採用年収\"] = 5000\n",
    "df_3.loc[df_3[\"後年収\"]>=50000000, \"後年収\"] = 50000000\n",
    "\n",
    "diff = df_3[\"後年収\"] - (df_3[\"前年収_採用年収\"] * 10000)\n",
    "#df_cs2[\"diff_cate\"] = pd.cut(diff, [-46563800, -1500000, -1000000, -500000, 0 , 500000, 1000000, 1500000, 2000000, 45000000])\n",
    "df_3[\"diff_cate\"] = pd.cut(diff, [-46563800, -500000, 0 , 500000, 1000000, 1500000, 2000000, 45000000])\n",
    "\n",
    "# カテゴリ区分リスト\n",
    "#cate_name = [\"0: -150以下\" ,\"1: -150 ～ -100\", \"2: -100 ～ -50\", \"3: -50 ～ 0\", \"4: 0 ～ 50\", \"5: 50 ～ 100\", \"6: 100 ～ 150\", \"7: 150 ～ 200\", \"8: 200以上\"]\n",
    "cate_name = [\"0: -50以下\" ,\"1: -50 ～ 0\", \"2: 0 ～ 50\", \"3: 50 ～ 100\", \"4: 100 ～ 150\", \"5: 150 ～ 200\", \"6: 200以上\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null件数の多い変数の穴埋め処理\n",
    "# これやらないでdropnaすると件数が激減する\n",
    "df_3.loc[df_3[\"雇用形態\"].isnull(), \"雇用形態\"] = \"なし\"\n",
    "df_3.loc[df_3[\"代表職種\"].isnull(), \"代表職種\"] = \"なし\"\n",
    "df_3.loc[df_3[\"経験業界名1\"].isnull(), \"経験業界名1\"] = \"なし\"\n",
    "df_3.loc[df_3[\"職務クラス\"].isnull(), \"職務クラス\"] = \"なし\"\n",
    "df_3.loc[df_3[\"語学\"].isnull(), \"語学\"] = \"なし\"\n",
    "df_3.loc[df_3[\"語学レベル_3段階\"].isnull(), \"語学レベル_3段階\"] = \"なし\"\n",
    "df_3.loc[df_3[\"資格1\"].isnull(), \"資格1\"] = \"なし\"\n",
    "df_3.loc[df_3[\"外資資本比率\"].isnull(), \"外資資本比率\"] = -1\n",
    "df_3.loc[df_3[\"求人語学\"].isnull(), \"求人語学\"] = \"なし\"\n",
    "df_3.loc[df_3[\"求人語学レベル\"].isnull(), \"求人語学レベル\"] = \"なし\"\n",
    "df_3.loc[df_3[\"年間賞与\"].isnull(), \"年間賞与\"] = \"なし\"\n",
    "df_3.loc[df_3[\"残業手当\"].isnull(), \"残業手当\"] = \"なし\"\n",
    "df_3.loc[df_3[\"住宅手当\"].isnull(), \"住宅手当\"] = \"なし\"\n",
    "df_3.loc[df_3[\"職種_転職前_小分類\"].isnull(), \"職種_転職前_小分類\"] = \"なし\"\n",
    "df_3.loc[df_3[\"職種_転職前_大分類\"].isnull(), \"職種_転職前_大分類\"] = \"なし\"\n",
    "df_3.loc[df_3[\"職種_転職後_小分類\"].isnull(), \"職種_転職後_小分類\"] = \"なし\"\n",
    "df_3.loc[df_3[\"職種_転職後_大分類\"].isnull(), \"職種_転職後_大分類\"] = \"なし\"\n",
    "df_3.loc[df_3[\"業種_転職前_小分類\"].isnull(), \"業種_転職前_小分類\"] = \"なし\"\n",
    "df_3.loc[df_3[\"業種_転職前_大分類\"].isnull(), \"業種_転職前_大分類\"] = \"なし\"\n",
    "df_3.loc[df_3[\"業種_転職後_小分類\"].isnull(), \"業種_転職後_小分類\"] = \"なし\"\n",
    "df_3.loc[df_3[\"業種_転職後_大分類\"].isnull(), \"業種_転職後_大分類\"] = \"なし\"\n",
    "\n",
    "# 転職後企業名を各企業の平均年収に変更する\n",
    "df_company_income = pd.DataFrame(index=[i for i in range(0,len(df_3.groupby(\"転職後_企業名\").mean()[\"後年収\"]))])\n",
    "df_company_income[\"転職後_企業名\"] = pd.DataFrame((df_3.groupby(\"転職後_企業名\").mean()[\"後年収\"]/10000).index)\n",
    "df_company_income[\"後年収\"] = pd.DataFrame((df_3.groupby(\"転職後_企業名\").mean()[\"後年収\"]/10000).values)\n",
    "#df_company_income = pd.DataFrame(df_3.groupby(\"転職後_企業名\").mean()[\"後年収\"]/10000)\n",
    "\n",
    "df_4 = pd.merge(df_3, df_company_income, on=\"転職後_企業名\", how=\"left\")\n",
    "df_4 = df_4.rename(columns={\"後年収_x\":\"後年収\", \"後年収_y\":\"転職後_企業平均年収\"})\n",
    "df_4.drop(\"転職後_企業名\", axis=1, inplace=True)\n",
    "#df_cs4.shape\n",
    "\n",
    "# 「年齢」と「年齢_5歳刻み」は情報としてかぶっているので「年齢」を削除する\n",
    "#df_4.drop([\"年齢_5歳刻み\"], axis=1, inplace=True)\n",
    "df_4.drop([\"年齢\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中央値計算\n",
    "df_before_jobtype_income = pd.DataFrame(index=[i for i in range(0,len(df_3.groupby(\"職種_転職前_小分類\").mean()[\"後年収\"]))])\n",
    "df_before_jobtype_income[\"職種_転職前_小分類\"] = pd.DataFrame((df_3.groupby(\"職種_転職前_小分類\").mean()[\"後年収\"]/10000).index)\n",
    "df_before_jobtype_income[\"後年収\"] = pd.DataFrame((df_3.groupby(\"職種_転職前_小分類\").mean()[\"後年収\"]/10000).values)\n",
    "\n",
    "df_after_jobtype_income   = pd.DataFrame(df_4.groupby(\"職種_転職後_小分類\").median()[\"後年収\"]/10000)\n",
    "df_after_jobtype_income[\"職種_転職後_小分類\"] = pd.DataFrame((df_3.groupby(\"職種_転職後_小分類\").mean()[\"後年収\"]/10000).index)\n",
    "df_after_jobtype_income[\"後年収\"] = pd.DataFrame((df_3.groupby(\"職種_転職後_小分類\").mean()[\"後年収\"]/10000).values)\n",
    "\n",
    "df_before_industry_income = pd.DataFrame(df_4.groupby(\"業種_転職前_小分類\").median()[\"後年収\"]/10000)\n",
    "df_before_industry_income[\"業種_転職前_小分類\"] = pd.DataFrame((df_3.groupby(\"業種_転職前_小分類\").mean()[\"後年収\"]/10000).index)\n",
    "df_before_industry_income[\"後年収\"] = pd.DataFrame((df_3.groupby(\"業種_転職前_小分類\").mean()[\"後年収\"]/10000).values)\n",
    "\n",
    "df_after_industry_income  = pd.DataFrame(df_4.groupby(\"業種_転職後_小分類\").median()[\"後年収\"]/10000)\n",
    "df_after_industry_income[\"業種_転職後_小分類\"] = pd.DataFrame((df_3.groupby(\"業種_転職後_小分類\").mean()[\"後年収\"]/10000).index)\n",
    "df_after_industry_income[\"後年収\"] = pd.DataFrame((df_3.groupby(\"業種_転職後_小分類\").mean()[\"後年収\"]/10000).values)\n",
    "\n",
    "# データ結合\n",
    "df_5 = pd.merge(df_4, df_before_jobtype_income,  on=\"職種_転職前_小分類\", how=\"left\", suffixes=[\"\", \"_1\"])\n",
    "df_5 = pd.merge(df_5, df_after_jobtype_income,   on=\"職種_転職後_小分類\", how=\"left\", suffixes=[\"\", \"_1\"])\n",
    "df_5 = pd.merge(df_5, df_before_industry_income, on=\"業種_転職前_小分類\", how=\"left\", suffixes=[\"\", \"_2\"])\n",
    "df_5 = pd.merge(df_5, df_after_industry_income,  on=\"業種_転職後_小分類\", how=\"left\", suffixes=[\"\", \"_2\"])\n",
    "\n",
    "# カラム名を変更\n",
    "df_5 = df_5.rename(columns={\n",
    "    \"前年収_採用年収_1\":\"職種_転職前_小分類_平均年収\",\n",
    "    \"後年収_1\":\"職種_転職後_小分類_平均年収\",\n",
    "    \"前年収_採用年収_2\":\"業種_転職前_小分類_平均年収\",\n",
    "    \"後年収_2\":\"業種_転職後_小分類_平均年収\"\n",
    "})\n",
    "\n",
    "# 小分類データを削除\n",
    "df_5.drop([\"職種_転職前_小分類\",\"職種_転職後_小分類\",\"業種_転職前_小分類\",\"業種_転職後_小分類\"], axis=1, inplace=True)\n",
    "#df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「後年収」を削除\n",
    "df_5.drop([\"後年収\"], axis=1, inplace=True)\n",
    "\n",
    "# NULL値を削除\n",
    "#df_6 = df_5.dropna()\n",
    "#df_6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_cols = [\n",
    "    \"求職者状態\",\n",
    "    \"サービスステータス\",\n",
    "    \"アクセス目的\",\n",
    "    \"アクセス手段\",\n",
    "    \"認知媒体\",\n",
    "    \"性別\",\n",
    "    \"都道府県名称\",\n",
    "    \"最終学歴\",\n",
    "    \"現職\",\n",
    "    \"雇用形態\",\n",
    "    \"代表職種\",\n",
    "    \"経験業界名1\",\n",
    "    \"職務クラス\",\n",
    "    \"語学\",\n",
    "    \"語学レベル_3段階\",\n",
    "    \"資格1\",\n",
    "    \"総合職FLG\",\n",
    "    \"求人語学\",\n",
    "    \"求人語学レベル\",\n",
    "    \"住所_都道府県\",\n",
    "    \"勤務地\",\n",
    "    \"求人業界1\",\n",
    "    \"職種_転職前_大分類\",\n",
    "    \"職種_転職後_大分類\",\n",
    "    \"業種_転職前_大分類\",\n",
    "    \"業種_転職後_大分類\",\n",
    "    \"年齢_5歳刻み\",\n",
    "    \"証券Ｃ\",\n",
    "    \"上場区分Ｃ\",\n",
    "    \"上場区分名\",\n",
    "    \"メイン業種分類Ｃ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-9213e3352637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df_ = pd.get_dummies(df_6.drop([\"diff_cate\"], axis=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mce_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"impute\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce_ohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"diff_cate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"diff_cate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"diff_cate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/category_encoders/one_hot.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordinal_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_invariant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/category_encoders/one_hot.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(self, X_in, cols)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mn_col_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_col_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                 \u001b[0mbin_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_col_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2149\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3861\u001b[0m             return self.reindex_indexer(new_axis=self.items[indexer],\n\u001b[1;32m   3862\u001b[0m                                         \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3863\u001b[0;31m                                         allow_dups=True)\n\u001b[0m\u001b[1;32m   3864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3865\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   4133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3832\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   4851\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4852\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 4853\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   4854\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4855\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   4874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4875\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4876\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4877\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ダミー変数化\n",
    "#df_ = pd.get_dummies(df_6.drop([\"diff_cate\"], axis=1))\n",
    "ce_ohe = ce.OneHotEncoder(cols=cat_features_cols, handle_unknown=\"impute\")\n",
    "df_ = ce_ohe.fit_transform(df_5.drop([\"diff_cate\"], axis=1))\n",
    "df_[\"diff_cate\"] = df_5[\"diff_cate\"]\n",
    "\n",
    "# 最終データとして設定\n",
    "df_fin1 = df_.copy()\n",
    "print(df_fin1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
